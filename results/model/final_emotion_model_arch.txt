FINAL EMOTION CLASSIFICATION MODEL ARCHITECTURE
================================================

Project: Real-Time Facial Emotion Recognition (FER2013 Dataset)
Goal Achieved: Test accuracy > 60% (final: 65.6%)
Model File: results/model/final_emotion_model.keras

1. ARCHITECTURE OVERVIEW
------------------------
Input: 48×48 grayscale images (1 channel), normalized to [0,1]
Backbone: 3 progressive convolutional blocks (VGG-style)
  - Filters: 32 → 64 → 128
  - Per block: Conv2D → BatchNorm → LeakyReLU(0.1) → Conv2D → BatchNorm → LeakyReLU(0.1) → MaxPooling2D → Dropout/SpatialDropout2D
Pooling: MaxPooling2D after each block
Flatten → Dense(256) → BatchNorm → LeakyReLU → Dropout(0.5)
Output: Dense(7, softmax) for 7-class classification

Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                      │ (None, 48, 48, 32)          │             320 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 48, 48, 32)          │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu (LeakyReLU)              │ (None, 48, 48, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 48, 48, 32)          │           9,248 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 48, 48, 32)          │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_1 (LeakyReLU)            │ (None, 48, 48, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d (MaxPooling2D)         │ (None, 24, 24, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 24, 24, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_2 (Conv2D)                    │ (None, 24, 24, 64)          │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_2                │ (None, 24, 24, 64)          │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_2 (LeakyReLU)            │ (None, 24, 24, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_3 (Conv2D)                    │ (None, 24, 24, 64)          │          36,928 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_3                │ (None, 24, 24, 64)          │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_3 (LeakyReLU)            │ (None, 24, 24, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_1 (MaxPooling2D)       │ (None, 12, 12, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ spatial_dropout2d (SpatialDropout2D) │ (None, 12, 12, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_4 (Conv2D)                    │ (None, 12, 12, 128)         │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_4                │ (None, 12, 12, 128)         │             512 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_4 (LeakyReLU)            │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_5 (Conv2D)                    │ (None, 12, 12, 128)         │         147,584 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_5                │ (None, 12, 12, 128)         │             512 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_5 (LeakyReLU)            │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_2 (MaxPooling2D)       │ (None, 6, 6, 128)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ spatial_dropout2d_1                  │ (None, 6, 6, 128)           │               0 │
│ (SpatialDropout2D)                   │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 4608)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (Dense)                        │ (None, 256)                 │       1,179,904 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_6                │ (None, 256)                 │           1,024 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_6 (LeakyReLU)            │ (None, 256)                 │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 256)                 │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 7)                   │           1,799 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 1,470,951 (5.61 MB)
 Trainable params: 1,469,543 (5.61 MB)
 Non-trainable params: 1,408 (5.50 KB)

Hyperparameters:
Batch size:     64
Learning rate:  0.001
Max epochs:     100
Optimizer:      Adam
Augmentation:   Yes (rotation±10°, shift/zoom 10%, hflip)\

2. KEY DESIGN DECISIONS
-----------------------
- LeakyReLU(α=0.1) used instead of ReLU → prevents dying neurons, better gradient flow on small/imbalanced FER2013 data
- BatchNormalization after every Conv → stabilizes activations and speeds convergence
- SpatialDropout2D(0.25–0.3) in deeper blocks → drops entire feature maps → stronger regularization against noisy labels
- Dropout(0.25–0.3) in conv blocks + Dropout(0.5) in dense layer → prevents overfitting
- Flatten + Dense(256) chosen over GlobalAveragePooling2D → GAP reduced accuracy (~63–64%); larger dense layer improved separation of ambiguous classes (Sad ↔ Neutral, Fear ↔ Surprise)
- MaxPooling instead of strided conv → preserves spatial hierarchy while reducing dimensions efficiently

3. HYPERPARAMETERS & TRAINING SETUP
-----------------------------------
Optimizer: Adam (initial lr=0.001)
Loss: Categorical Crossentropy
Batch size: 64
Callbacks:
  - EarlyStopping(patience=8, min_delta=0.001, restore_best_weights=True)
  - ModelCheckpoint(monitor='val_accuracy', save_best_only=True)
  - ReduceLROnPlateau(factor=0.5, patience=4, cooldown=2, min_lr=1e-6)
Training time: ~70 minutes on Colab T4 GPU
Total parameters: ~1.4 million

4. ITERATION HISTORY & MODEL SELECTION
--------------------------------------
Experiment 000 – Baseline CNN
  - 2 conv blocks (32→64), Dense(128)
  - Test acc: ~57–58%
  - Issue: underfitting, mild overfitting after ~18 epochs
  - Decision: too shallow → increase depth

Experiment 001 – Deeper CNN
  - Added 3rd block (128 filters)
  - Test acc: ~62%
  - Decision: clear improvement → continue deepening

Experiment 002 – VGG-style stacking
  - Each block: 2 conv layers
  - Test acc: ~64%
  - Decision: richer features → new baseline

Experiment 003 – VGG + SpatialDropout2D + Dense(256)
  - Added SpatialDropout2D(0.25–0.3), increased dense to 256
  - Test acc: 65.5–65.7% (most consistent runs)
  - Decision: best balance of capacity, regularization, and stability → SELECTED AS FINAL MODEL

Experiment 004 – 4-block variant (added 256-filter block)
  - Test acc: ~66.4%
  - Issue: slight gain but unstable validation curves
  - Decision: dropped (diminishing returns, risk of overfitting)

Experiments 005–009 – Ablations (GAP, multi-dense, dropout tuning)
  - Test acc: ~63–64%
  - Decision: confirmed Flatten + single Dense(256) outperforms alternatives

Final selection rationale:
  Experiment 003 consistently delivered 65–66% test accuracy with stable training curves and early stopping before overfitting.
  It provides sufficient depth for hierarchical features, strong regularization for noisy/imbalanced data, and adequate classifier capacity for ambiguous emotions.

5. FINAL PERFORMANCE METRICS
----------------------------
Training Accuracy (final epoch): ~68%
Validation Accuracy: ~66%
Test Accuracy (test_with_emotions.csv): 65.6%
Training Time: ~70 minutes (Colab T4 GPU)
Parameters: ~1.4 million

This architecture represents the optimal trade-off between model capacity, generalization, and training stability for the FER2013 emotion detection task under the given constraints.